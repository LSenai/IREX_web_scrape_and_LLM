{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "OKnFDSVOluWU"
      ],
      "authorship_tag": "ABX9TyNe2Wj/2RhqDzcKkpzMEdES"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75mKYoyG28DW",
        "outputId": "bd170404-73f4-4760-e11c-c0cc51d79f2a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "API_KEY = os.getenv(\"API_KEY\")"
      ],
      "metadata": {
        "id": "qZSKvPQJ3S4Q"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Crawl and Scrape"
      ],
      "metadata": {
        "id": "OKnFDSVOluWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import time"
      ],
      "metadata": {
        "id": "SixstQLMEPTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scrape all sections dynamically\n"
      ],
      "metadata": {
        "id": "hv3xBF4uYDWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jicCEIXAQbG"
      },
      "outputs": [],
      "source": [
        "def scrape_dynamic_sections(url):\n",
        "    \"\"\"Scrape all sections from a project page except 'Contact'.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch {url}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    sections = soup.find_all('section')\n",
        "    results = {\"URL\": url}\n",
        "\n",
        "    for section in sections:\n",
        "        # Locate the section heading\n",
        "        heading = section.find('h2')\n",
        "        if not heading:\n",
        "            continue\n",
        "\n",
        "        section_title = heading.text.strip()\n",
        "        if \"contact\" in section_title.lower():  # Skip 'Contact' section\n",
        "            continue\n",
        "\n",
        "        # Extract section content\n",
        "        heading.decompose()  # Remove heading from the content\n",
        "        content = section.get_text(strip=True)\n",
        "        results[section_title] = content\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Extract Related Resources Links"
      ],
      "metadata": {
        "id": "XekZPfzMb8TW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_related_resources(url):\n",
        "    \"\"\"Extract links from the 'Related Resources' section.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch {url}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    related_resources_section = None\n",
        "\n",
        "    for h2 in soup.find_all('h2'):\n",
        "        if \"related resources\" in h2.text.strip().lower():\n",
        "            related_resources_section = h2.find_parent('section')\n",
        "            break\n",
        "\n",
        "    if not related_resources_section:\n",
        "        return []\n",
        "\n",
        "    # Extract links\n",
        "    links = []\n",
        "    for a_tag in related_resources_section.find_all('a', href=True):\n",
        "        href = a_tag['href']\n",
        "        full_url = href if href.startswith('http') else f\"https://www.irex.org{href}\"\n",
        "        links.append(full_url)\n",
        "\n",
        "    return links\n",
        "\n",
        "def scrape_partners_links(url):\n",
        "    \"\"\"Extract links from the 'Partners' section.\"\"\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Failed to fetch {url}\")\n",
        "        return None\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'html.parser')\n",
        "    partners_section = None\n",
        "\n",
        "    for h2 in soup.find_all('h2'):\n",
        "        if \"partners\" in h2.text.strip().lower():\n",
        "            partners_section = h2.find_parent('section')\n",
        "            break\n",
        "\n",
        "    if not partners_section:\n",
        "        return []\n",
        "\n",
        "    # Extract links\n",
        "    links = []\n",
        "    for a_tag in partners_section.find_all('a', href=True):\n",
        "        href = a_tag['href']\n",
        "        full_url = href if href.startswith('http') else f\"https://www.irex.org{href}\"\n",
        "        links.append(full_url)\n",
        "\n",
        "    return links\n"
      ],
      "metadata": {
        "id": "QkLu70KGb76F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scrape_project_page(url):\n",
        "    \"\"\"Scrape all sections and related resources, including partners, from a project page.\"\"\"\n",
        "    sections = scrape_dynamic_sections(url)\n",
        "    related_resources = scrape_related_resources(url)\n",
        "    partners_links = scrape_partners_links(url)\n",
        "\n",
        "    if sections:\n",
        "        sections[\"Related Resources\"] = \", \".join(related_resources) if related_resources else \"None\"\n",
        "        sections[\"Partners Links\"] = \", \".join(partners_links) if partners_links else \"None\"\n",
        "    return sections\n"
      ],
      "metadata": {
        "id": "VYhF2v9xcA3v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_project_links(base_url, max_pages):\n",
        "    \"\"\"Fetch all project links from paginated pages.\"\"\"\n",
        "    all_links = []\n",
        "\n",
        "    for page in range(max_pages + 1):  # Iterate through pages 0 to max_pages\n",
        "        page_url = f\"{base_url}?page={page}\"\n",
        "        print(f\"Fetching links from: {page_url}\")\n",
        "\n",
        "        response = requests.get(page_url)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to fetch {page_url}\")\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "\n",
        "        # Find all project links on the current page\n",
        "        for a_tag in soup.find_all('a', href=True):\n",
        "            href = a_tag['href']\n",
        "            if '/project/' in href:  # Filter links matching the project pattern\n",
        "                full_url = href if href.startswith('http') else f\"https://www.irex.org{href}\"\n",
        "                all_links.append(full_url)\n",
        "\n",
        "    return list(set(all_links))  # Remove duplicates\n",
        "\n",
        "def crawl_projects(base_url, max_pages):\n",
        "    \"\"\"Crawl project pages and extract structured data.\"\"\"\n",
        "    project_links = fetch_project_links(base_url, max_pages)\n",
        "    print(f\"Found {len(project_links)} project links.\")\n",
        "\n",
        "    all_project_data = []\n",
        "\n",
        "    for idx, link in enumerate(project_links):\n",
        "        print(f\"Processing {idx + 1}/{len(project_links)}: {link}\")\n",
        "        try:\n",
        "            project_data = scrape_project_page(link)\n",
        "            if project_data:\n",
        "                all_project_data.append(project_data)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {link}: {e}\")\n",
        "\n",
        "        time.sleep(1)  # Be polite and avoid overwhelming the server\n",
        "\n",
        "    return all_project_data\n",
        "\n",
        "# Crawl the site\n",
        "MAX_PAGES = 12  # Adjust based on pagination\n",
        "BASE_URL = \"https://www.irex.org/our-work\"\n",
        "project_data = crawl_projects(BASE_URL, MAX_PAGES)\n",
        "\n",
        "# Save the data to an Excel file\n",
        "df = pd.DataFrame(project_data)\n",
        "df.to_excel(\"irex_projects.xlsx\", index=False)\n",
        "print(\"Data saved to irex_projects_with_partners.xlsx\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcbAQsg_cEuo",
        "outputId": "f14f998e-a0b7-4dfe-d4e1-0d6dd1ed800e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fetching links from: https://www.irex.org/our-work?page=0\n",
            "Fetching links from: https://www.irex.org/our-work?page=1\n",
            "Fetching links from: https://www.irex.org/our-work?page=2\n",
            "Fetching links from: https://www.irex.org/our-work?page=3\n",
            "Fetching links from: https://www.irex.org/our-work?page=4\n",
            "Fetching links from: https://www.irex.org/our-work?page=5\n",
            "Fetching links from: https://www.irex.org/our-work?page=6\n",
            "Fetching links from: https://www.irex.org/our-work?page=7\n",
            "Fetching links from: https://www.irex.org/our-work?page=8\n",
            "Fetching links from: https://www.irex.org/our-work?page=9\n",
            "Fetching links from: https://www.irex.org/our-work?page=10\n",
            "Fetching links from: https://www.irex.org/our-work?page=11\n",
            "Fetching links from: https://www.irex.org/our-work?page=12\n",
            "Found 97 project links.\n",
            "Processing 1/97: https://www.irex.org/project/usaid-media-program\n",
            "Processing 2/97: https://www.irex.org/project/media-empowerment-democratic-sri-lanka-mend\n",
            "Processing 3/97: https://www.irex.org/project/civil-society-and-media-leadership-program-liberia-csml\n",
            "Processing 4/97: https://www.irex.org/project/learn-discern\n",
            "Processing 5/97: https://www.irex.org/project/proyecto-accion-transformadora\n",
            "Processing 6/97: https://www.irex.org/project/learn-discern-education-l2d-ed-strengthening-resilience-information-manipulation\n",
            "Processing 7/97: https://www.irex.org/project/skills-virtual-gigs\n",
            "Processing 8/97: https://www.irex.org/project/tafakkar-think\n",
            "Processing 9/97: https://www.irex.org/project/ukraine-veteran-reintegration\n",
            "Processing 10/97: https://www.irex.org/project/policy-ukraine-local-self-governance-pulse\n",
            "Processing 11/97: https://www.irex.org/project/ukraine-rapid-response-fund\n",
            "Processing 12/97: https://www.irex.org/project/youmakken-youth-media-action-knowledge-and-engagement-program\n",
            "Processing 13/97: https://www.irex.org/project/cyla-cohesion-through-youth-led-action\n",
            "Processing 14/97: https://www.irex.org/project/university-administration-support-program-uasp\n",
            "Processing 15/97: https://www.irex.org/project/encouraging-inclusive-public-participation-near-eastern-affairs-region-eipp\n",
            "Processing 16/97: https://www.irex.org/project/pamoja-founders-project-accelerating-african-entrepreneurs-impact\n",
            "Processing 17/97: https://www.irex.org/project/mandela-washington-fellowship-young-african-leaders\n",
            "Processing 18/97: https://www.irex.org/project/national-models-womens-safety-online-nmwso\n",
            "Processing 19/97: https://www.irex.org/project/tech-age-girls\n",
            "Processing 20/97: https://www.irex.org/project/iraq-university-linkages-program\n",
            "Processing 21/97: https://www.irex.org/project/youth-essential-skills-training-youth-succeed-school-work-and-leadership\n",
            "Processing 22/97: https://www.irex.org/project/youthink-media-literacy-north-macedonia\n",
            "Processing 23/97: https://www.irex.org/project/visiting-american-professionals-iraq-vap\n",
            "Processing 24/97: https://www.irex.org/project/morocco-career-center-program\n",
            "Processing 25/97: https://www.irex.org/project/community-solutions\n",
            "Processing 26/97: https://www.irex.org/project/ukraine-media-partnership-program-umpp\n",
            "Processing 27/97: https://www.irex.org/project/trafficking-persons-legal-assistance-program-tip-lap\n",
            "Processing 28/97: https://www.irex.org/project/ma3an\n",
            "Processing 29/97: https://www.irex.org/project/thomas-jefferson-scholarship-program-tjsp\n",
            "Processing 30/97: https://www.irex.org/project/global-undergraduate-exchange-program-pakistan-global-ugrad-pakistan\n",
            "Processing 31/97: https://www.irex.org/project/forsah-tvet\n",
            "Processing 32/97: https://www.irex.org/project/usaid-early-grade-education-activity-asas\n",
            "Processing 33/97: https://www.irex.org/project/novateca-global-libraries-moldova\n",
            "Processing 34/97: https://www.irex.org/project/kenya-covid-19-resourcing-data-project-crdp\n",
            "Processing 35/97: https://www.irex.org/project/first-mile-irexs-framework-promoting-safer-migration\n",
            "Processing 36/97: https://www.irex.org/project/kenya-play-kplay-project\n",
            "Processing 37/97: https://www.irex.org/project/strengthening-media-systems\n",
            "Processing 38/97: https://www.irex.org/project/youth-excel-our-knowledge-leading-change\n",
            "Processing 39/97: https://www.irex.org/project/promoting-positive-information-sri-lanka-pro-info\n",
            "Processing 40/97: https://www.irex.org/project/libraries-development\n",
            "Processing 41/97: https://www.irex.org/project/youth-represent-democratic-republic-congo-drc\n",
            "Processing 42/97: https://www.irex.org/project/us-research-scholar-visa-sponsorship\n",
            "Processing 43/97: https://www.irex.org/project/stem-green-labs\n",
            "Processing 44/97: https://www.irex.org/project/fulbright-teacher-exchanges\n",
            "Processing 45/97: https://www.irex.org/project/america-house-and-american-spaces-ukraine\n",
            "Processing 46/97: https://www.irex.org/project/transform-digital-spaces-transform-activity\n",
            "Processing 47/97: https://www.irex.org/project/usaid-preservice-teacher-education-jordan\n",
            "Processing 48/97: https://www.irex.org/project/macedonia-media-leaders-program\n",
            "Processing 49/97: https://www.irex.org/project/united-voices-action-20\n",
            "Processing 50/97: https://www.irex.org/project/girls-learning-through-technology-gltt\n",
            "Processing 51/97: https://www.irex.org/project/strengthening-content-connections\n",
            "Processing 52/97: https://www.irex.org/project/communities-thrive-irex-read-global-partnership\n",
            "Processing 53/97: https://www.irex.org/project/media-transparent-and-accountable-governance-m-tag\n",
            "Processing 54/97: https://www.irex.org/project/us-jordan-leadership-exchange-program\n",
            "Processing 55/97: https://www.irex.org/project/global-solutions\n",
            "Processing 56/97: https://www.irex.org/project/internet-freedom-festival\n",
            "Processing 57/97: https://www.irex.org/project/climate-finance-fellowship\n",
            "Processing 58/97: https://www.irex.org/project/design-hub-information-central-asia\n",
            "Processing 59/97: https://www.irex.org/project/world-smarts-stem-challenge\n",
            "Processing 60/97: https://www.irex.org/project/private-sector-led-workforce-development-activity-kosovo\n",
            "Processing 61/97: https://www.irex.org/project/essential-skills-soft-skills-changing-world\n",
            "Processing 62/97: https://www.irex.org/project/creating-content-connections-moldova\n",
            "Processing 63/97: https://www.irex.org/project/data-zetu-amplifying-tanzanians-voices-through-information\n",
            "Processing 64/97: https://www.irex.org/project/medijiinovacije-serbia-media-innovation-activity\n",
            "Processing 65/97: https://www.irex.org/project/regional-assistance-program\n",
            "Processing 66/97: https://www.irex.org/project/ukraine-national-identity-through-youth-unity\n",
            "Processing 67/97: https://www.irex.org/project/usaid-higher-education-innovation-growth\n",
            "Processing 68/97: https://www.irex.org/project/media-clubs\n",
            "Processing 69/97: https://www.irex.org/project/navigator-supporting-safe-migration-nepal\n",
            "Processing 70/97: https://www.irex.org/project/world-smarts-changemakers\n",
            "Processing 71/97: https://www.irex.org/project/mozambique-media-strengthening-program-msp\n",
            "Processing 72/97: https://www.irex.org/project/media-literacy-training-teachers\n",
            "Processing 73/97: https://www.irex.org/project/citizen-engagement-and-reform-communication\n",
            "Processing 74/97: https://www.irex.org/project/russian-language-television-content-fund-rltcf\n",
            "Processing 75/97: https://www.irex.org/project/young-leaders-americas-initiative-ylai-program\n",
            "Processing 76/97: https://www.irex.org/project/irexs-global-framework-addressing-online-threats-womens-public-participation\n",
            "Processing 77/97: https://www.irex.org/project/families-digital-age-fada\n",
            "Processing 78/97: https://www.irex.org/project/global-solutions-stem-challenge\n",
            "Processing 79/97: https://www.irex.org/project/community-engagement-exchange\n",
            "Processing 80/97: https://www.irex.org/project/training-educators-excellence\n",
            "Processing 81/97: https://www.irex.org/project/climate-talent-initiative-cti\n",
            "Processing 82/97: https://www.irex.org/project/stabilization-through-media-partnerships-stmp\n",
            "Processing 83/97: https://www.irex.org/project/data-leaders-d4l-practical-skills-data-informed-decision-making\n",
            "Processing 84/97: https://www.irex.org/project/employee-essential-skills-soft-skills-training-employees\n",
            "Processing 85/97: https://www.irex.org/project/credible-voces-de-la-juventud\n",
            "Processing 86/97: https://www.irex.org/project/investing-african-journalism-iaj\n",
            "Processing 87/97: https://www.irex.org/project/safe-securing-access-free-expression\n",
            "Processing 88/97: https://www.irex.org/project/fellowships-alumni-network-study-fans\n",
            "Processing 89/97: https://www.irex.org/project/us-iraq-higher-education-partnerships-program\n",
            "Processing 90/97: https://www.irex.org/project/mums-project\n",
            "Processing 91/97: https://www.irex.org/project/comunitatea-mea-my-community\n",
            "Processing 92/97: https://www.irex.org/project/elections-and-democracy-activity-liberia\n",
            "Processing 93/97: https://www.irex.org/project/civil-society-and-media-strengthened-together-and-advancing-new-directions\n",
            "Processing 94/97: https://www.irex.org/project/georgian-media-partnership-program-gmpp\n",
            "Processing 95/97: https://www.irex.org/project/yedyna-hromada-united-community\n",
            "Processing 96/97: https://www.irex.org/project/beyond-access\n",
            "Processing 97/97: https://www.irex.org/project/esm3ni-listen-me\n",
            "Data saved to irex_projects_with_partners.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Use LLM for classification and summarization"
      ],
      "metadata": {
        "id": "8CmfD5Xhl0sm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install requests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCTxjk8JlayB",
        "outputId": "0c096fe4-db7f-493d-9294-5b2900add5ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "# Hugging Face Inference API details\n",
        "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
        "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
        "\n",
        "def classify_relevance(text):\n",
        "    \"\"\"\n",
        "    Classify relevance using the improved prompt with examples.\n",
        "    \"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Determine if the following project is relevant to digital development or ICT4D. Respond only with 'Yes' or 'No'—do not provide any explanation.\n",
        "\n",
        "    Examples:\n",
        "    1. A project that uses ICT tools to improve education outcomes for rural students is relevant. Answer: Yes\n",
        "    2. A project focused only on providing food aid during a crisis is not relevant. Answer: No\n",
        "    3. A project that trains teachers on using digital platforms to deliver lessons is relevant. Answer: Yes\n",
        "    4. A project addressing gender-based violence without any digital component is not relevant. Answer: No\n",
        "\n",
        "    Text: {text}\n",
        "    \"\"\"\n",
        "    payload = {\"inputs\": prompt, \"parameters\": {\"return_full_text\": False }}\n",
        "    response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result[0][\"generated_text\"].strip()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "rNeZUgGOmGLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_summary(text):\n",
        "    \"\"\"\n",
        "    Use Hugging Face Inference API to generate a summary for relevant projects.\n",
        "    \"\"\"\n",
        "    payload = {\n",
        "        \"inputs\": f\"\"\"\n",
        "        Summarize the following project, including:\n",
        "        - Project Name\n",
        "        - Description\n",
        "        - Key Statistics\n",
        "        - Additional details about people, partners, and resources (if available).\n",
        "\n",
        "        Text: {text}\n",
        "        \"\"\"\n",
        "    }\n",
        "    response = requests.post(API_URL, headers=HEADERS, json=payload)\n",
        "    if response.status_code == 200:\n",
        "        result = response.json()\n",
        "        return result[0][\"generated_text\"].strip()\n",
        "    else:\n",
        "        print(f\"Error: {response.status_code} - {response.text}\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "8WyXfhL1mOiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_excel(\"irex_projects.xlsx\")\n",
        "\n",
        "# Columns to include for classification and summarization\n",
        "relevant_columns = [\n",
        "    \"Overview\", \"Goals\", \"Project Activities\", \"Quick Facts\", \"How It Works\",\n",
        "    \"Activities\", \"Results\", \"Evidence and Results\", \"Success Stories\",\n",
        "    \"Initiative Highlights\", \"Goals and Objectives\", \"Training Options\",\n",
        "    \"Activities and Timeline\", \"Case Study: A Tech Company in Nigeria\"\n",
        "]\n",
        "\n",
        "# Filter and combine relevant fields\n",
        "df[\"Combined Text\"] = df[relevant_columns].fillna(\"\").apply(\" \".join, axis=1)\n"
      ],
      "metadata": {
        "id": "nCAU1zDomTXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply classification to determine relevance\n",
        "df[\"Relevance\"] = df[\"Combined Text\"].apply(classify_relevance)\n",
        "\n",
        "# Save the results\n",
        "df.to_excel(\"classified_projects.xlsx\", index=False)\n",
        "print(\"Relevance classification completed and saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOQnk9W7mVr5",
        "outputId": "a2a19817-a7b8-40d0-f2cf-a2db34b7031d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Relevance classification completed and saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text = \"IREX’s Girls’ Learning Through Technology (GLTT) project in Kenya uses a technology-based approach to support girls’ education and development of ICT skills in low-tech schools.\"\n",
        "response = classify_relevance(test_text)\n",
        "print(f\"Response: {response}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSK1XeNAvKMk",
        "outputId": "5e1db00d-a3ef-4ae9-f80b-1c96ef0e6482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Response: Answer: Yes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter for relevant projects\n",
        "relevant_projects = df[df[\"Relevance\"] == \"Yes\"]\n",
        "\n",
        "# Generate summaries for relevant projects\n",
        "relevant_projects[\"Summary\"] = relevant_projects[\"Combined Text\"].apply(generate_summary)\n",
        "\n",
        "# Save the summarized data\n",
        "relevant_projects.to_excel(\"relevant_projects_with_summaries.xlsx\", index=False)\n",
        "print(\"Summarization completed and saved!\")\n"
      ],
      "metadata": {
        "id": "kHO9Qp5hmX9W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}